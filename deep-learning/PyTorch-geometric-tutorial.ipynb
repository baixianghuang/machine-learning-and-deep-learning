{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Geometric Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 4], x=[3, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "# A single graph in PyTorch Geometric is described by an instance of torch_geometric.data.Data\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 4], x=[3, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If edge_index are tuples, transpose it\n",
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [1, 2],\n",
    "                           [2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(data.num_nodes)\n",
    "print(data.num_edges)\n",
    "print(data.is_directed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 6 3\n",
      "Data(edge_index=[2, 168], x=[37, 3], y=[1])\n"
     ]
    }
   ],
   "source": [
    "# The first graph in the ENZYMES dataset contains 37 nodes, each one having 3 features. There are 168/2 = 84 \n",
    "# undirected edges and the graph is assigned to exactly one class\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "print(len(dataset), dataset.num_classes, dataset.num_node_features)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 7 1433\n",
      "Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset2 = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "print(len(dataset2), dataset2.num_classes, dataset2.num_node_features)\n",
    "print(dataset2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[1051], edge_index=[2, 4036], x=[1051, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1094], edge_index=[2, 4228], x=[1094, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1047], edge_index=[2, 3616], x=[1047, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1044], edge_index=[2, 4170], x=[1044, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[948], edge_index=[2, 3666], x=[948, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1040], edge_index=[2, 4030], x=[1040, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[953], edge_index=[2, 3610], x=[953, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[985], edge_index=[2, 3746], x=[985, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1017], edge_index=[2, 3834], x=[1017, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1092], edge_index=[2, 4106], x=[1092, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[990], edge_index=[2, 3792], x=[990, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1183], edge_index=[2, 4306], x=[1183, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1021], edge_index=[2, 3944], x=[1021, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1016], edge_index=[2, 4000], x=[1016, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1087], edge_index=[2, 4124], x=[1087, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1117], edge_index=[2, 4318], x=[1117, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1112], edge_index=[2, 4080], x=[1112, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1092], edge_index=[2, 4160], x=[1092, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[691], edge_index=[2, 2798], x=[691, 3], y=[24])\n",
      "24\n",
      "torch.Size([24, 3])\n"
     ]
    }
   ],
   "source": [
    "from torch_scatter import scatter_mean\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "for data in loader:\n",
    "    print(data)\n",
    "    print(data.num_graphs)\n",
    "    print(scatter_mean(data.x, data.batch, dim=0).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(category=[1], pos=[2518, 3], x=[2518, 3], y=[2518])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'])\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The `pre_transform` argument differs from the one used in the pre-processed version of this dataset. If you really want to make use of another pre-processing technique, make sure to delete `/tmp/ShapeNet/processed` first.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(category=[1], pos=[2518, 3], x=[2518, 3], y=[2518])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the point cloud dataset into a graph dataset by generating nearest neighbor graphs from the point clouds via transforms\n",
    "import torch_geometric.transforms as T\n",
    "dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'],\n",
    "                    pre_transform=T.KNNGraph(k=6))\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The `pre_transform` argument differs from the one used in the pre-processed version of this dataset. If you really want to make use of another pre-processing technique, make sure to delete `/tmp/ShapeNet/processed` first.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(category=[1], pos=[2518, 3], x=[2518, 3], y=[2518])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'],\n",
    "                    pre_transform=T.KNNGraph(k=6),\n",
    "                    transform=T.RandomTranslate(0.01))\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple 2-layer GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8030\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / int(data.test_mask.sum())\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps of Message Passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = GCNConv(16, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class EdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EdgeConv, self).__init__(aggr='max') #  \"Max\" aggregation.\n",
    "        self.mlp = Seq(Linear(2 * in_channels, out_channels),\n",
    "                       ReLU(),\n",
    "                       Linear(out_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        # x_i has shape [E, in_channels]\n",
    "        # x_j has shape [E, in_channels]\n",
    "\n",
    "        tmp = torch.cat([x_i, x_j - x_i], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
    "        return self.mlp(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "class DynamicEdgeConv(EdgeConv):\n",
    "    def __init__(self, in_channels, out_channels, k=6):\n",
    "        super(DynamicEdgeConv, self).__init__(in_channels, out_channels)\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x, batch=None):\n",
    "        edge_index = knn_graph(x, self.k, batch, loop=False, flow=self.flow)\n",
    "        return super(DynamicEdgeConv, self).forward(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(MyOwnDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = [...]\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-26-128d225f5d8d>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-128d225f5d8d>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    def process(self):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Dataset\n",
    "\n",
    "class MyOwnDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(MyOwnDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_1.pt', 'data_2.pt', ...]\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "\n",
    "    def process(self):\n",
    "        i = 0\n",
    "        for raw_path in self.raw_paths:\n",
    "            # Read data from `raw_path`.\n",
    "            data = Data(...)\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            torch.save(data, osp.join(self.processed_dir, 'data_{}.pt'.format(i)))\n",
    "            i += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
